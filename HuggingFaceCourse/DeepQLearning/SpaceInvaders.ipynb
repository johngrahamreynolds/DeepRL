{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johngrahamreynolds/DeepRL/blob/main/HuggingFaceCourse/DeepQLearning/SpaceInvaders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7xBVPzoXxOg"
      },
      "source": [
        "# Unit 3: Deep Q-Learning with Atari Games üëæ using RL Baselines3 Zoo\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/thumbnail.jpg\" alt=\"Unit 3 Thumbnail\">\n",
        "\n",
        "In this notebook, **you'll train a Deep Q-Learning agent** playing Space Invaders using [RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo), a training framework based on [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/) that provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.\n",
        "\n",
        "We're using the [RL-Baselines-3 Zoo integration, a vanilla version of Deep Q-Learning](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html) with no extensions such as Double-DQN, Dueling-DQN, and Prioritized Experience Replay.\n",
        "\n",
        "‚¨áÔ∏è Here is an example of what **you will achieve** ‚¨áÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9S713biXntc"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<video controls autoplay><source src=\"https://huggingface.co/ThomasSimonini/ppo-SpaceInvadersNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéÆ Environments:\n",
        "\n",
        "- [SpacesInvadersNoFrameskip-v4](https://gymnasium.farama.org/environments/atari/space_invaders/)\n",
        "\n",
        "You can see the difference between Space Invaders versions here üëâ https://gymnasium.farama.org/environments/atari/space_invaders/#variants\n",
        "\n",
        "### üìö RL-Library:\n",
        "\n",
        "- [RL-Baselines3-Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)"
      ],
      "metadata": {
        "id": "ykJiGevCMVc5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wciHGjrFYz9m"
      },
      "source": [
        "## Objectives of this notebook üèÜ\n",
        "At the end of the notebook, you will:\n",
        "- Be able to understand deeper **how RL Baselines3 Zoo works**.\n",
        "- Be able to **push your trained agent and the code to the Hub** with a nice video replay and an evaluation score üî•.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook is from Deep Reinforcement Learning Course\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>"
      ],
      "metadata": {
        "id": "TsnP0rjxMn1e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw6fJHIAZd-J"
      },
      "source": [
        "In this free course, you will:\n",
        "\n",
        "- üìñ Study Deep Reinforcement Learning in **theory and practice**.\n",
        "- üßë‚Äçüíª Learn to **use famous Deep RL libraries** such as Stable Baselines3, RL Baselines3 Zoo, CleanRL and Sample Factory 2.0.\n",
        "- ü§ñ Train **agents in unique environments**\n",
        "\n",
        "And more check üìö the syllabus üëâ https://simoninithomas.github.io/deep-rl-course\n",
        "\n",
        "Don‚Äôt forget to **<a href=\"http://eepurl.com/ic5ZUD\">sign up to the course</a>** (we are collecting your email to be able to¬†**send you the links when each Unit is published and give you information about the challenges and updates).**\n",
        "\n",
        "\n",
        "The best way to keep in touch is to join our discord server to exchange with the community and with us üëâüèª https://discord.gg/ydHrjt3WP5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vgANIBBZg1p"
      },
      "source": [
        "## Prerequisites üèóÔ∏è\n",
        "Before diving into the notebook, you need to:\n",
        "\n",
        "üî≤ üìö **[Study Deep Q-Learning by reading Unit 3](https://huggingface.co/deep-rl-course/unit3/introduction)**  ü§ó"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues)."
      ],
      "metadata": {
        "id": "7kszpGFaRVhq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR0jZtYreSI5"
      },
      "source": [
        "# Let's train a Deep Q-Learning agent playing Atari' Space Invaders üëæ and upload it to the Hub.\n",
        "\n",
        "We strongly recommend students **to use Google Colab for the hands-on exercises instead of running them on their personal computers**.\n",
        "\n",
        "By using Google Colab, **you can focus on learning and experimenting without worrying about the technical aspects of setting up your environments**.\n",
        "\n",
        "To validate this hands-on for the certification process, you need to push your trained model to the Hub and **get a result of >= 200**.\n",
        "\n",
        "To find your result, go to the leaderboard and find your model, **the result = mean_reward - std of reward**\n",
        "\n",
        "For more information about the certification process, check this section üëâ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An advice üí°\n",
        "It's better to run this colab in a copy on your Google Drive, so that **if it timeouts** you still have the saved notebook on your Google Drive and do not need to fill everything from scratch.\n",
        "\n",
        "To do that you can either do `Ctrl + S` or `File > Save a copy in Google Drive.`\n",
        "\n",
        "Also, we're going to **train it for 90 minutes with 1M timesteps**. By typing `!nvidia-smi` will tell you what GPU you're using.\n",
        "\n",
        "And if you want to train more such 10 million steps, this will take about 9 hours, potentially resulting in Colab timing out. In that case, I recommend running this on your local computer (or somewhere else). Just click on: `File>Download`."
      ],
      "metadata": {
        "id": "Nc8BnyVEc3Ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the GPU üí™\n",
        "- To **accelerate the agent's training, we'll use a GPU**. To do that, go to `Runtime > Change Runtime type`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">"
      ],
      "metadata": {
        "id": "PU4FVzaoM6fC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `Hardware Accelerator > GPU`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">"
      ],
      "metadata": {
        "id": "KV0NyFdQM9ZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "jqB9T2Kv-qmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install RL-Baselines3 Zoo and its dependencies üìö\n",
        "\n",
        "If you see `ERROR: pip's dependency resolver does not currently take into account all the packages that are installed.` **this is normal and it's not a critical error** there's a conflict of version. But the packages we need are installed."
      ],
      "metadata": {
        "id": "wS_cVefO-aYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/DLR-RM/rl-baselines3-zoo"
      ],
      "metadata": {
        "id": "S1A_E4z3awa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install swig cmake ffmpeg"
      ],
      "metadata": {
        "id": "8_MllY6Om1eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S9mJiKg6SqC"
      },
      "source": [
        "To be able to use Atari games in Gymnasium we need to install atari package. And accept-rom-license to download the rom files (games files)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[atari]\n",
        "!pip install gymnasium[accept-rom-license]"
      ],
      "metadata": {
        "id": "NsRP-lX1_2fC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00838305-5a1b-4dcd-f4bc-b4024870834d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.0.4)\n",
            "Collecting ale_py>=0.9 (from gymnasium[atari])\n",
            "  Downloading ale_py-0.11.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (9.0 kB)\n",
            "Downloading ale_py-0.11.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ale_py\n",
            "  Attempting uninstall: ale_py\n",
            "    Found existing installation: ale-py 0.8.1\n",
            "    Uninstalling ale-py-0.8.1:\n",
            "      Successfully uninstalled ale-py-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ale_py-0.11.2\n",
            "Requirement already satisfied: gymnasium[accept-rom-license] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "\u001b[33mWARNING: gymnasium 1.1.1 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license]) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license]) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a virtual display üîΩ\n",
        "\n",
        "During the notebook, we'll need to generate a replay video. To do so, with colab, **we need to have a virtual screen to be able to render the environment** (and thus record the frames).\n",
        "\n",
        "Hence the following cell will install the librairies and create and run a virtual screen üñ•"
      ],
      "metadata": {
        "id": "bTpYcVZVMzUI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV6wjQ7Be7p5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt install python-opengl\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "id": "BE5JWP5rQIKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iPgzluo9z-u"
      },
      "source": [
        "## Train our Deep Q-Learning Agent to Play Space Invaders üëæ\n",
        "\n",
        "To train an agent with RL-Baselines3-Zoo, we just need to do two things:\n",
        "\n",
        "1. Create a hyperparameter config file that will contain our training hyperparameters called `dqn.yml`.\n",
        "\n",
        "This is a template example:\n",
        "\n",
        "```\n",
        "SpaceInvadersNoFrameskip-v4:\n",
        "  env_wrapper:\n",
        "    - stable_baselines3.common.atari_wrappers.AtariWrapper\n",
        "  frame_stack: 4\n",
        "  policy: 'CnnPolicy'\n",
        "  n_timesteps: !!float 1e6\n",
        "  buffer_size: 100000\n",
        "  learning_rate: !!float 1e-4\n",
        "  batch_size: 32\n",
        "  learning_starts: 100000\n",
        "  target_update_interval: 1000\n",
        "  train_freq: 4\n",
        "  gradient_steps: 1\n",
        "  exploration_fraction: 0.1\n",
        "  exploration_final_eps: 0.01\n",
        "  # If True, you need to deactivate handle_timeout_termination\n",
        "  # in the replay_buffer_kwargs\n",
        "  optimize_memory_usage: False\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VjblFSVDQOj"
      },
      "source": [
        "Here we see that:\n",
        "- We use the `Atari Wrapper` that preprocess the input (Frame reduction ,grayscale, stack 4 frames)\n",
        "- We use `CnnPolicy`, since we use Convolutional layers to process the frames\n",
        "- We train it for 10 million `n_timesteps`\n",
        "- Memory (Experience Replay) size is 100000, aka the amount of experience steps you saved to train again your agent with.\n",
        "\n",
        "üí° My advice is to **reduce the training timesteps to 1M,** which will take about 90 minutes on a P100. `!nvidia-smi` will tell you what GPU you're using. At 10 million steps, this will take about 9 hours, which could likely result in Colab timing out. I recommend running this on your local computer (or somewhere else). Just click on: `File>Download`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qTkbWrkECOJ"
      },
      "source": [
        "In terms of hyperparameters optimization, my advice is to focus on these 3 hyperparameters:\n",
        "- `learning_rate`\n",
        "- `buffer_size (Experience Memory size)`\n",
        "- `batch_size`\n",
        "\n",
        "As a good practice, you need to **check the documentation to understand what each hyperparameters does**: https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html#parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn8bRTHvERRL"
      },
      "source": [
        "2. We start the training and save the models on `logs` folder üìÅ\n",
        "\n",
        "- Define the algorithm after `--algo`, where we save the model after `-f` and where the hyperparameter config is after `-c`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xr1TVW4xfbz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "396f63e4-8801-4605-af55-ab631e92f9b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "| time/               |          |\n",
            "|    episodes         | 2716     |\n",
            "|    fps              | 230      |\n",
            "|    time_elapsed     | 2643     |\n",
            "|    total_timesteps  | 609091   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0565   |\n",
            "|    n_updates        | 127272   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.41e+03 |\n",
            "|    ep_rew_mean      | 469      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2720     |\n",
            "|    fps              | 230      |\n",
            "|    time_elapsed     | 2648     |\n",
            "|    total_timesteps  | 610240   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.017    |\n",
            "|    n_updates        | 127559   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.39e+03 |\n",
            "|    ep_rew_mean      | 469      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2724     |\n",
            "|    fps              | 230      |\n",
            "|    time_elapsed     | 2653     |\n",
            "|    total_timesteps  | 611395   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0196   |\n",
            "|    n_updates        | 127848   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 470      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2728     |\n",
            "|    fps              | 230      |\n",
            "|    time_elapsed     | 2659     |\n",
            "|    total_timesteps  | 612674   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.024    |\n",
            "|    n_updates        | 128168   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.39e+03 |\n",
            "|    ep_rew_mean      | 466      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2732     |\n",
            "|    fps              | 230      |\n",
            "|    time_elapsed     | 2665     |\n",
            "|    total_timesteps  | 613868   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0334   |\n",
            "|    n_updates        | 128466   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 472      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2736     |\n",
            "|    fps              | 230      |\n",
            "|    time_elapsed     | 2673     |\n",
            "|    total_timesteps  | 615727   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0169   |\n",
            "|    n_updates        | 128931   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 473      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2740     |\n",
            "|    fps              | 230      |\n",
            "|    time_elapsed     | 2677     |\n",
            "|    total_timesteps  | 616677   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.05     |\n",
            "|    n_updates        | 129169   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.37e+03 |\n",
            "|    ep_rew_mean      | 470      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2744     |\n",
            "|    fps              | 230      |\n",
            "|    time_elapsed     | 2683     |\n",
            "|    total_timesteps  | 618082   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0172   |\n",
            "|    n_updates        | 129520   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.38e+03 |\n",
            "|    ep_rew_mean      | 472      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2748     |\n",
            "|    fps              | 230      |\n",
            "|    time_elapsed     | 2688     |\n",
            "|    total_timesteps  | 619136   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.031    |\n",
            "|    n_updates        | 129783   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 469      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2752     |\n",
            "|    fps              | 230      |\n",
            "|    time_elapsed     | 2693     |\n",
            "|    total_timesteps  | 620365   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0247   |\n",
            "|    n_updates        | 130091   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.39e+03 |\n",
            "|    ep_rew_mean      | 469      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2756     |\n",
            "|    fps              | 230      |\n",
            "|    time_elapsed     | 2700     |\n",
            "|    total_timesteps  | 621902   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0296   |\n",
            "|    n_updates        | 130475   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 474      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2760     |\n",
            "|    fps              | 230      |\n",
            "|    time_elapsed     | 2706     |\n",
            "|    total_timesteps  | 623196   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.015    |\n",
            "|    n_updates        | 130798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.41e+03 |\n",
            "|    ep_rew_mean      | 467      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2764     |\n",
            "|    fps              | 230      |\n",
            "|    time_elapsed     | 2711     |\n",
            "|    total_timesteps  | 624394   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0179   |\n",
            "|    n_updates        | 131098   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=625000, episode_reward=547.00 +/- 150.15\n",
            "Episode length: 3680.40 +/- 666.09\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.68e+03 |\n",
            "|    mean_reward      | 547      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 625000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0429   |\n",
            "|    n_updates        | 131249   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 469      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2768     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2727     |\n",
            "|    total_timesteps  | 625674   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0331   |\n",
            "|    n_updates        | 131418   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 470      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2772     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2732     |\n",
            "|    total_timesteps  | 626780   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0182   |\n",
            "|    n_updates        | 131694   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 472      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2776     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2738     |\n",
            "|    total_timesteps  | 628127   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0201   |\n",
            "|    n_updates        | 132031   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 474      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2780     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2743     |\n",
            "|    total_timesteps  | 629315   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0206   |\n",
            "|    n_updates        | 132328   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 471      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2784     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2749     |\n",
            "|    total_timesteps  | 630624   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0272   |\n",
            "|    n_updates        | 132655   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 466      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2788     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2753     |\n",
            "|    total_timesteps  | 631594   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0147   |\n",
            "|    n_updates        | 132898   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.41e+03 |\n",
            "|    ep_rew_mean      | 465      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2792     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2758     |\n",
            "|    total_timesteps  | 632597   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0248   |\n",
            "|    n_updates        | 133149   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 465      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2796     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2763     |\n",
            "|    total_timesteps  | 633593   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0242   |\n",
            "|    n_updates        | 133398   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 467      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2800     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2770     |\n",
            "|    total_timesteps  | 635186   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0418   |\n",
            "|    n_updates        | 133796   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 464      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2804     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2775     |\n",
            "|    total_timesteps  | 636370   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0274   |\n",
            "|    n_updates        | 134092   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 467      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2808     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2784     |\n",
            "|    total_timesteps  | 638346   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0242   |\n",
            "|    n_updates        | 134586   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 466      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2812     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2790     |\n",
            "|    total_timesteps  | 639648   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0142   |\n",
            "|    n_updates        | 134911   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 461      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2816     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2798     |\n",
            "|    total_timesteps  | 641384   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0585   |\n",
            "|    n_updates        | 135345   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 467      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2820     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2804     |\n",
            "|    total_timesteps  | 642781   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0272   |\n",
            "|    n_updates        | 135695   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 467      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2824     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2808     |\n",
            "|    total_timesteps  | 643571   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0114   |\n",
            "|    n_updates        | 135892   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 467      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2828     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2814     |\n",
            "|    total_timesteps  | 644947   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0147   |\n",
            "|    n_updates        | 136236   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 468      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2832     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2819     |\n",
            "|    total_timesteps  | 646099   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0363   |\n",
            "|    n_updates        | 136524   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 469      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2836     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2825     |\n",
            "|    total_timesteps  | 647403   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0588   |\n",
            "|    n_updates        | 136850   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 469      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2840     |\n",
            "|    fps              | 229      |\n",
            "|    time_elapsed     | 2831     |\n",
            "|    total_timesteps  | 648869   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0234   |\n",
            "|    n_updates        | 137217   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=650000, episode_reward=566.00 +/- 66.81\n",
            "Episode length: 3507.00 +/- 467.66\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.51e+03 |\n",
            "|    mean_reward      | 566      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 650000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0226   |\n",
            "|    n_updates        | 137499   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 470      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2844     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2846     |\n",
            "|    total_timesteps  | 650181   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0207   |\n",
            "|    n_updates        | 137545   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 477      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2848     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2850     |\n",
            "|    total_timesteps  | 651057   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0173   |\n",
            "|    n_updates        | 137764   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.52e+03 |\n",
            "|    ep_rew_mean      | 480      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2852     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2856     |\n",
            "|    total_timesteps  | 652376   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0412   |\n",
            "|    n_updates        | 138093   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 478      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2856     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2862     |\n",
            "|    total_timesteps  | 653641   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0287   |\n",
            "|    n_updates        | 138410   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.51e+03 |\n",
            "|    ep_rew_mean      | 482      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2860     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2868     |\n",
            "|    total_timesteps  | 655066   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0288   |\n",
            "|    n_updates        | 138766   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.52e+03 |\n",
            "|    ep_rew_mean      | 486      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2864     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2871     |\n",
            "|    total_timesteps  | 655638   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0107   |\n",
            "|    n_updates        | 138909   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 488      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2868     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2876     |\n",
            "|    total_timesteps  | 656687   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.019    |\n",
            "|    n_updates        | 139171   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.54e+03 |\n",
            "|    ep_rew_mean      | 489      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2872     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2881     |\n",
            "|    total_timesteps  | 657776   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0321   |\n",
            "|    n_updates        | 139443   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.54e+03 |\n",
            "|    ep_rew_mean      | 487      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2876     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2885     |\n",
            "|    total_timesteps  | 658853   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0184   |\n",
            "|    n_updates        | 139713   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 488      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2880     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2891     |\n",
            "|    total_timesteps  | 660101   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0203   |\n",
            "|    n_updates        | 140025   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.51e+03 |\n",
            "|    ep_rew_mean      | 486      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2884     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2896     |\n",
            "|    total_timesteps  | 661192   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0214   |\n",
            "|    n_updates        | 140297   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 490      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2888     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2903     |\n",
            "|    total_timesteps  | 662682   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0992   |\n",
            "|    n_updates        | 140670   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 491      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2892     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2907     |\n",
            "|    total_timesteps  | 663606   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0156   |\n",
            "|    n_updates        | 140901   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.51e+03 |\n",
            "|    ep_rew_mean      | 488      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2896     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2911     |\n",
            "|    total_timesteps  | 664663   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0243   |\n",
            "|    n_updates        | 141165   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.48e+03 |\n",
            "|    ep_rew_mean      | 484      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2900     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2916     |\n",
            "|    total_timesteps  | 665679   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0188   |\n",
            "|    n_updates        | 141419   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 486      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2904     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2922     |\n",
            "|    total_timesteps  | 666929   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.019    |\n",
            "|    n_updates        | 141732   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 478      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2908     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2927     |\n",
            "|    total_timesteps  | 668019   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0173   |\n",
            "|    n_updates        | 142004   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 479      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2912     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2934     |\n",
            "|    total_timesteps  | 669799   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0306   |\n",
            "|    n_updates        | 142449   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 477      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2916     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2940     |\n",
            "|    total_timesteps  | 671004   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0147   |\n",
            "|    n_updates        | 142750   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 484      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2920     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2946     |\n",
            "|    total_timesteps  | 672512   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0214   |\n",
            "|    n_updates        | 143127   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 485      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2924     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2953     |\n",
            "|    total_timesteps  | 673988   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.023    |\n",
            "|    n_updates        | 143496   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 486      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2928     |\n",
            "|    fps              | 228      |\n",
            "|    time_elapsed     | 2958     |\n",
            "|    total_timesteps  | 674999   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0466   |\n",
            "|    n_updates        | 143749   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=675000, episode_reward=476.00 +/- 166.51\n",
            "Episode length: 3588.80 +/- 898.20\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 3.59e+03 |\n",
            "|    mean_reward     | 476      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 675000   |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 488      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2932     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 2974     |\n",
            "|    total_timesteps  | 676282   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0184   |\n",
            "|    n_updates        | 144070   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 487      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2936     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 2977     |\n",
            "|    total_timesteps  | 677002   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0182   |\n",
            "|    n_updates        | 144250   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 491      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2940     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 2983     |\n",
            "|    total_timesteps  | 678383   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0202   |\n",
            "|    n_updates        | 144595   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 491      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2944     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 2988     |\n",
            "|    total_timesteps  | 679607   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0413   |\n",
            "|    n_updates        | 144901   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.49e+03 |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2948     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 2992     |\n",
            "|    total_timesteps  | 680466   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0212   |\n",
            "|    n_updates        | 145116   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 490      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2952     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 2998     |\n",
            "|    total_timesteps  | 681900   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0298   |\n",
            "|    n_updates        | 145474   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 491      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2956     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3005     |\n",
            "|    total_timesteps  | 683444   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0397   |\n",
            "|    n_updates        | 145860   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.48e+03 |\n",
            "|    ep_rew_mean      | 492      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2960     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3009     |\n",
            "|    total_timesteps  | 684359   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0212   |\n",
            "|    n_updates        | 146089   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.48e+03 |\n",
            "|    ep_rew_mean      | 493      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2964     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3013     |\n",
            "|    total_timesteps  | 685248   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0208   |\n",
            "|    n_updates        | 146311   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.49e+03 |\n",
            "|    ep_rew_mean      | 494      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2968     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3018     |\n",
            "|    total_timesteps  | 686456   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.018    |\n",
            "|    n_updates        | 146613   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.51e+03 |\n",
            "|    ep_rew_mean      | 498      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2972     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3024     |\n",
            "|    total_timesteps  | 687731   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0226   |\n",
            "|    n_updates        | 146932   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.51e+03 |\n",
            "|    ep_rew_mean      | 498      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2976     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3029     |\n",
            "|    total_timesteps  | 688793   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0192   |\n",
            "|    n_updates        | 147198   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.52e+03 |\n",
            "|    ep_rew_mean      | 499      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2980     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3037     |\n",
            "|    total_timesteps  | 690619   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0193   |\n",
            "|    n_updates        | 147654   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 499      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2984     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3040     |\n",
            "|    total_timesteps  | 691328   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0226   |\n",
            "|    n_updates        | 147831   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2988     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3047     |\n",
            "|    total_timesteps  | 692994   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0292   |\n",
            "|    n_updates        | 148248   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 498      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2992     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3052     |\n",
            "|    total_timesteps  | 694122   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0229   |\n",
            "|    n_updates        | 148530   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2996     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3060     |\n",
            "|    total_timesteps  | 695717   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0308   |\n",
            "|    n_updates        | 148929   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.52e+03 |\n",
            "|    ep_rew_mean      | 499      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3000     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3065     |\n",
            "|    total_timesteps  | 697008   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0117   |\n",
            "|    n_updates        | 149251   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.51e+03 |\n",
            "|    ep_rew_mean      | 499      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3004     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3071     |\n",
            "|    total_timesteps  | 698194   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0231   |\n",
            "|    n_updates        | 149548   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3008     |\n",
            "|    fps              | 227      |\n",
            "|    time_elapsed     | 3075     |\n",
            "|    total_timesteps  | 699290   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0174   |\n",
            "|    n_updates        | 149822   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=700000, episode_reward=495.00 +/- 127.67\n",
            "Episode length: 3899.20 +/- 833.89\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.9e+03  |\n",
            "|    mean_reward      | 495      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 700000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0176   |\n",
            "|    n_updates        | 149999   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.49e+03 |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3012     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3093     |\n",
            "|    total_timesteps  | 700781   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0141   |\n",
            "|    n_updates        | 150195   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3016     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3098     |\n",
            "|    total_timesteps  | 701868   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0249   |\n",
            "|    n_updates        | 150466   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.51e+03 |\n",
            "|    ep_rew_mean      | 492      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3020     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3102     |\n",
            "|    total_timesteps  | 702952   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0145   |\n",
            "|    n_updates        | 150737   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.52e+03 |\n",
            "|    ep_rew_mean      | 493      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3024     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3108     |\n",
            "|    total_timesteps  | 704132   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0104   |\n",
            "|    n_updates        | 151032   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 489      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3028     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3111     |\n",
            "|    total_timesteps  | 704832   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0587   |\n",
            "|    n_updates        | 151207   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.49e+03 |\n",
            "|    ep_rew_mean      | 490      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3032     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3115     |\n",
            "|    total_timesteps  | 705807   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0204   |\n",
            "|    n_updates        | 151451   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.48e+03 |\n",
            "|    ep_rew_mean      | 488      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3036     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3121     |\n",
            "|    total_timesteps  | 706942   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0245   |\n",
            "|    n_updates        | 151735   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 484      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3040     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3125     |\n",
            "|    total_timesteps  | 707970   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0166   |\n",
            "|    n_updates        | 151992   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 483      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3044     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3131     |\n",
            "|    total_timesteps  | 709333   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.018    |\n",
            "|    n_updates        | 152333   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 481      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3048     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3134     |\n",
            "|    total_timesteps  | 710012   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0222   |\n",
            "|    n_updates        | 152502   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 485      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3052     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3139     |\n",
            "|    total_timesteps  | 711207   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0133   |\n",
            "|    n_updates        | 152801   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 486      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3056     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3148     |\n",
            "|    total_timesteps  | 713122   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0238   |\n",
            "|    n_updates        | 153280   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 487      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3060     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3152     |\n",
            "|    total_timesteps  | 714144   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0171   |\n",
            "|    n_updates        | 153535   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 485      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3064     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3157     |\n",
            "|    total_timesteps  | 715159   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0267   |\n",
            "|    n_updates        | 153789   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 482      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3068     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3163     |\n",
            "|    total_timesteps  | 716503   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0877   |\n",
            "|    n_updates        | 154125   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 484      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3072     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3166     |\n",
            "|    total_timesteps  | 717208   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0193   |\n",
            "|    n_updates        | 154301   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 484      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3076     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3174     |\n",
            "|    total_timesteps  | 718965   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0478   |\n",
            "|    n_updates        | 154741   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 487      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3080     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3179     |\n",
            "|    total_timesteps  | 720181   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0185   |\n",
            "|    n_updates        | 155045   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 486      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3084     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3185     |\n",
            "|    total_timesteps  | 721555   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.018    |\n",
            "|    n_updates        | 155388   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 488      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3088     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3193     |\n",
            "|    total_timesteps  | 723225   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0591   |\n",
            "|    n_updates        | 155806   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 491      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3092     |\n",
            "|    fps              | 226      |\n",
            "|    time_elapsed     | 3198     |\n",
            "|    total_timesteps  | 724417   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0221   |\n",
            "|    n_updates        | 156104   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=725000, episode_reward=459.00 +/- 116.85\n",
            "Episode length: 3321.60 +/- 560.12\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.32e+03 |\n",
            "|    mean_reward      | 459      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 725000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0167   |\n",
            "|    n_updates        | 156249   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 490      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3096     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3212     |\n",
            "|    total_timesteps  | 725599   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.017    |\n",
            "|    n_updates        | 156399   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 491      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3100     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3219     |\n",
            "|    total_timesteps  | 727111   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0267   |\n",
            "|    n_updates        | 156777   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 490      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3104     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3224     |\n",
            "|    total_timesteps  | 728353   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0388   |\n",
            "|    n_updates        | 157088   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 488      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3108     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3230     |\n",
            "|    total_timesteps  | 729557   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0244   |\n",
            "|    n_updates        | 157389   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 491      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3112     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3238     |\n",
            "|    total_timesteps  | 731291   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0202   |\n",
            "|    n_updates        | 157822   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3116     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3242     |\n",
            "|    total_timesteps  | 732349   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0126   |\n",
            "|    n_updates        | 158087   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 499      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3120     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3250     |\n",
            "|    total_timesteps  | 734049   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.016    |\n",
            "|    n_updates        | 158512   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 500      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3124     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3254     |\n",
            "|    total_timesteps  | 734942   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0241   |\n",
            "|    n_updates        | 158735   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 499      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3128     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3260     |\n",
            "|    total_timesteps  | 736491   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0182   |\n",
            "|    n_updates        | 159122   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 498      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3132     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3266     |\n",
            "|    total_timesteps  | 737750   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0486   |\n",
            "|    n_updates        | 159437   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3136     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3270     |\n",
            "|    total_timesteps  | 738565   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0263   |\n",
            "|    n_updates        | 159641   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 499      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3140     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3275     |\n",
            "|    total_timesteps  | 739756   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0195   |\n",
            "|    n_updates        | 159938   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3144     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3279     |\n",
            "|    total_timesteps  | 740667   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0312   |\n",
            "|    n_updates        | 160166   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 500      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3148     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3285     |\n",
            "|    total_timesteps  | 741986   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0145   |\n",
            "|    n_updates        | 160496   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 500      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3152     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3289     |\n",
            "|    total_timesteps  | 742967   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0206   |\n",
            "|    n_updates        | 160741   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 499      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3156     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3295     |\n",
            "|    total_timesteps  | 744360   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0174   |\n",
            "|    n_updates        | 161089   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 495      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3160     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3301     |\n",
            "|    total_timesteps  | 745504   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0204   |\n",
            "|    n_updates        | 161375   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3164     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3306     |\n",
            "|    total_timesteps  | 746620   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0178   |\n",
            "|    n_updates        | 161654   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3168     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3313     |\n",
            "|    total_timesteps  | 748220   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0189   |\n",
            "|    n_updates        | 162054   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 493      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3172     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3316     |\n",
            "|    total_timesteps  | 749005   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0119   |\n",
            "|    n_updates        | 162251   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=750000, episode_reward=437.00 +/- 184.95\n",
            "Episode length: 3310.80 +/- 1002.81\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.31e+03 |\n",
            "|    mean_reward      | 437      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 750000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0182   |\n",
            "|    n_updates        | 162499   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 494      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3176     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3332     |\n",
            "|    total_timesteps  | 750691   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0575   |\n",
            "|    n_updates        | 162672   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3180     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3339     |\n",
            "|    total_timesteps  | 752107   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0399   |\n",
            "|    n_updates        | 163026   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 495      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3184     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3344     |\n",
            "|    total_timesteps  | 753312   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0488   |\n",
            "|    n_updates        | 163327   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3188     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3352     |\n",
            "|    total_timesteps  | 755156   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0528   |\n",
            "|    n_updates        | 163788   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.49e+03 |\n",
            "|    ep_rew_mean      | 495      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3192     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3355     |\n",
            "|    total_timesteps  | 755756   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0109   |\n",
            "|    n_updates        | 163938   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 490      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3196     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3359     |\n",
            "|    total_timesteps  | 756632   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0483   |\n",
            "|    n_updates        | 164157   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 488      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3200     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3366     |\n",
            "|    total_timesteps  | 758159   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.041    |\n",
            "|    n_updates        | 164539   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 488      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3204     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3371     |\n",
            "|    total_timesteps  | 759266   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0237   |\n",
            "|    n_updates        | 164816   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 491      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3208     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3378     |\n",
            "|    total_timesteps  | 760960   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0181   |\n",
            "|    n_updates        | 165239   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 493      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3212     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3384     |\n",
            "|    total_timesteps  | 762308   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0163   |\n",
            "|    n_updates        | 165576   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 489      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3216     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3388     |\n",
            "|    total_timesteps  | 763249   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0132   |\n",
            "|    n_updates        | 165812   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 488      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3220     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3393     |\n",
            "|    total_timesteps  | 764276   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0476   |\n",
            "|    n_updates        | 166068   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 488      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3224     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3399     |\n",
            "|    total_timesteps  | 765543   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0213   |\n",
            "|    n_updates        | 166385   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 491      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3228     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3404     |\n",
            "|    total_timesteps  | 766699   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0187   |\n",
            "|    n_updates        | 166674   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 486      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3232     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3408     |\n",
            "|    total_timesteps  | 767499   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0317   |\n",
            "|    n_updates        | 166874   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.41e+03 |\n",
            "|    ep_rew_mean      | 485      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3236     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3413     |\n",
            "|    total_timesteps  | 768694   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0213   |\n",
            "|    n_updates        | 167173   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.41e+03 |\n",
            "|    ep_rew_mean      | 485      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3240     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3419     |\n",
            "|    total_timesteps  | 770022   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.019    |\n",
            "|    n_updates        | 167505   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 487      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3244     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3423     |\n",
            "|    total_timesteps  | 770824   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0564   |\n",
            "|    n_updates        | 167705   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 483      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3248     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3427     |\n",
            "|    total_timesteps  | 771752   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0346   |\n",
            "|    n_updates        | 167937   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 482      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3252     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3432     |\n",
            "|    total_timesteps  | 772863   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0258   |\n",
            "|    n_updates        | 168215   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.39e+03 |\n",
            "|    ep_rew_mean      | 484      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3256     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3438     |\n",
            "|    total_timesteps  | 774206   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0206   |\n",
            "|    n_updates        | 168551   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.37e+03 |\n",
            "|    ep_rew_mean      | 477      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3260     |\n",
            "|    fps              | 225      |\n",
            "|    time_elapsed     | 3440     |\n",
            "|    total_timesteps  | 774621   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0168   |\n",
            "|    n_updates        | 168655   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=775000, episode_reward=413.00 +/- 174.52\n",
            "Episode length: 3362.60 +/- 970.19\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.36e+03 |\n",
            "|    mean_reward      | 413      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 775000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0411   |\n",
            "|    n_updates        | 168749   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.37e+03 |\n",
            "|    ep_rew_mean      | 479      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3264     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3457     |\n",
            "|    total_timesteps  | 776364   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0493   |\n",
            "|    n_updates        | 169090   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.37e+03 |\n",
            "|    ep_rew_mean      | 481      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3268     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3463     |\n",
            "|    total_timesteps  | 777905   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0169   |\n",
            "|    n_updates        | 169476   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.36e+03 |\n",
            "|    ep_rew_mean      | 481      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3272     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3469     |\n",
            "|    total_timesteps  | 779024   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0113   |\n",
            "|    n_updates        | 169755   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.35e+03 |\n",
            "|    ep_rew_mean      | 480      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3276     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3474     |\n",
            "|    total_timesteps  | 780333   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0416   |\n",
            "|    n_updates        | 170083   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.36e+03 |\n",
            "|    ep_rew_mean      | 481      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3280     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3478     |\n",
            "|    total_timesteps  | 781088   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0148   |\n",
            "|    n_updates        | 170271   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.36e+03 |\n",
            "|    ep_rew_mean      | 480      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3284     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3483     |\n",
            "|    total_timesteps  | 782266   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0134   |\n",
            "|    n_updates        | 170566   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.36e+03 |\n",
            "|    ep_rew_mean      | 480      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3288     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3488     |\n",
            "|    total_timesteps  | 783392   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0343   |\n",
            "|    n_updates        | 170847   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.34e+03 |\n",
            "|    ep_rew_mean      | 476      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3292     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3494     |\n",
            "|    total_timesteps  | 784612   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0174   |\n",
            "|    n_updates        | 171152   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.35e+03 |\n",
            "|    ep_rew_mean      | 477      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3296     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3498     |\n",
            "|    total_timesteps  | 785499   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0185   |\n",
            "|    n_updates        | 171374   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.35e+03 |\n",
            "|    ep_rew_mean      | 477      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3300     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3502     |\n",
            "|    total_timesteps  | 786466   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.018    |\n",
            "|    n_updates        | 171616   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.37e+03 |\n",
            "|    ep_rew_mean      | 483      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3304     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3510     |\n",
            "|    total_timesteps  | 788369   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0199   |\n",
            "|    n_updates        | 172092   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.38e+03 |\n",
            "|    ep_rew_mean      | 482      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3308     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3515     |\n",
            "|    total_timesteps  | 789418   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0205   |\n",
            "|    n_updates        | 172354   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 492      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3312     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3525     |\n",
            "|    total_timesteps  | 791648   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0214   |\n",
            "|    n_updates        | 172911   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 495      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3316     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3531     |\n",
            "|    total_timesteps  | 792893   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.024    |\n",
            "|    n_updates        | 173223   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 495      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3320     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3537     |\n",
            "|    total_timesteps  | 794362   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0191   |\n",
            "|    n_updates        | 173590   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 501      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3324     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3540     |\n",
            "|    total_timesteps  | 795063   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0624   |\n",
            "|    n_updates        | 173765   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3328     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3548     |\n",
            "|    total_timesteps  | 796903   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.05     |\n",
            "|    n_updates        | 174225   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 493      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3332     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3553     |\n",
            "|    total_timesteps  | 797916   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0171   |\n",
            "|    n_updates        | 174478   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 492      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3336     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3558     |\n",
            "|    total_timesteps  | 799071   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0188   |\n",
            "|    n_updates        | 174767   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 491      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3340     |\n",
            "|    fps              | 224      |\n",
            "|    time_elapsed     | 3562     |\n",
            "|    total_timesteps  | 799921   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0525   |\n",
            "|    n_updates        | 174980   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=800000, episode_reward=556.00 +/- 130.36\n",
            "Episode length: 3818.60 +/- 737.75\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.82e+03 |\n",
            "|    mean_reward      | 556      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 800000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0526   |\n",
            "|    n_updates        | 174999   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3344     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3578     |\n",
            "|    total_timesteps  | 801278   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0239   |\n",
            "|    n_updates        | 175319   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3348     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3584     |\n",
            "|    total_timesteps  | 802676   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0102   |\n",
            "|    n_updates        | 175668   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 499      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3352     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3590     |\n",
            "|    total_timesteps  | 803912   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0286   |\n",
            "|    n_updates        | 175977   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3356     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3594     |\n",
            "|    total_timesteps  | 804884   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0359   |\n",
            "|    n_updates        | 176220   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 495      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3360     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3601     |\n",
            "|    total_timesteps  | 806394   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0397   |\n",
            "|    n_updates        | 176598   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 495      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3364     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3603     |\n",
            "|    total_timesteps  | 807033   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0133   |\n",
            "|    n_updates        | 176758   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 492      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3368     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3608     |\n",
            "|    total_timesteps  | 808165   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.026    |\n",
            "|    n_updates        | 177041   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 490      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3372     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3615     |\n",
            "|    total_timesteps  | 809678   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0273   |\n",
            "|    n_updates        | 177419   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 490      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3376     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3619     |\n",
            "|    total_timesteps  | 810578   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0158   |\n",
            "|    n_updates        | 177644   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 486      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3380     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3626     |\n",
            "|    total_timesteps  | 812039   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0197   |\n",
            "|    n_updates        | 178009   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 487      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3384     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3631     |\n",
            "|    total_timesteps  | 813342   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0253   |\n",
            "|    n_updates        | 178335   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 486      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3388     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3636     |\n",
            "|    total_timesteps  | 814276   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0143   |\n",
            "|    n_updates        | 178568   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 484      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3392     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3642     |\n",
            "|    total_timesteps  | 815783   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0164   |\n",
            "|    n_updates        | 178945   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 488      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3396     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3649     |\n",
            "|    total_timesteps  | 817288   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0442   |\n",
            "|    n_updates        | 179321   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 490      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3400     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3660     |\n",
            "|    total_timesteps  | 819561   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0719   |\n",
            "|    n_updates        | 179890   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 490      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3404     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3666     |\n",
            "|    total_timesteps  | 820984   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0246   |\n",
            "|    n_updates        | 180245   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 487      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3408     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3670     |\n",
            "|    total_timesteps  | 821810   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0154   |\n",
            "|    n_updates        | 180452   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 485      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3412     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3674     |\n",
            "|    total_timesteps  | 822730   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0419   |\n",
            "|    n_updates        | 180682   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 491      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3416     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3681     |\n",
            "|    total_timesteps  | 824262   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0375   |\n",
            "|    n_updates        | 181065   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=825000, episode_reward=428.00 +/- 145.52\n",
            "Episode length: 3634.60 +/- 221.91\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.63e+03 |\n",
            "|    mean_reward      | 428      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 825000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.014    |\n",
            "|    n_updates        | 181249   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 489      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3420     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3696     |\n",
            "|    total_timesteps  | 825302   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0244   |\n",
            "|    n_updates        | 181325   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 488      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3424     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3699     |\n",
            "|    total_timesteps  | 826064   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0642   |\n",
            "|    n_updates        | 181515   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.48e+03 |\n",
            "|    ep_rew_mean      | 492      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3428     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3707     |\n",
            "|    total_timesteps  | 827796   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.027    |\n",
            "|    n_updates        | 181948   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 494      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3432     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3714     |\n",
            "|    total_timesteps  | 829256   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0398   |\n",
            "|    n_updates        | 182313   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.51e+03 |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3436     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3720     |\n",
            "|    total_timesteps  | 830633   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0396   |\n",
            "|    n_updates        | 182658   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.52e+03 |\n",
            "|    ep_rew_mean      | 498      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3440     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3724     |\n",
            "|    total_timesteps  | 831628   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0252   |\n",
            "|    n_updates        | 182906   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.52e+03 |\n",
            "|    ep_rew_mean      | 499      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3444     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3730     |\n",
            "|    total_timesteps  | 832855   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0764   |\n",
            "|    n_updates        | 183213   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3448     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3733     |\n",
            "|    total_timesteps  | 833518   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0181   |\n",
            "|    n_updates        | 183379   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3452     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3739     |\n",
            "|    total_timesteps  | 834820   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0165   |\n",
            "|    n_updates        | 183704   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.51e+03 |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3456     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3744     |\n",
            "|    total_timesteps  | 835927   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0435   |\n",
            "|    n_updates        | 183981   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.51e+03 |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3460     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3751     |\n",
            "|    total_timesteps  | 837644   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0302   |\n",
            "|    n_updates        | 184410   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3464     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3761     |\n",
            "|    total_timesteps  | 839818   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0262   |\n",
            "|    n_updates        | 184954   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.54e+03 |\n",
            "|    ep_rew_mean      | 505      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3468     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3767     |\n",
            "|    total_timesteps  | 841220   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0188   |\n",
            "|    n_updates        | 185304   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.52e+03 |\n",
            "|    ep_rew_mean      | 503      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3472     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3771     |\n",
            "|    total_timesteps  | 842088   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0183   |\n",
            "|    n_updates        | 185521   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.54e+03 |\n",
            "|    ep_rew_mean      | 507      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3476     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3776     |\n",
            "|    total_timesteps  | 843172   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0214   |\n",
            "|    n_updates        | 185792   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 504      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3480     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3780     |\n",
            "|    total_timesteps  | 844004   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0288   |\n",
            "|    n_updates        | 186000   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.51e+03 |\n",
            "|    ep_rew_mean      | 499      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3484     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3784     |\n",
            "|    total_timesteps  | 845065   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0697   |\n",
            "|    n_updates        | 186266   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.52e+03 |\n",
            "|    ep_rew_mean      | 501      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3488     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3789     |\n",
            "|    total_timesteps  | 846172   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0283   |\n",
            "|    n_updates        | 186542   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 499      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3492     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3797     |\n",
            "|    total_timesteps  | 847961   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0489   |\n",
            "|    n_updates        | 186990   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 498      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3496     |\n",
            "|    fps              | 223      |\n",
            "|    time_elapsed     | 3804     |\n",
            "|    total_timesteps  | 849341   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0191   |\n",
            "|    n_updates        | 187335   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=850000, episode_reward=521.00 +/- 184.02\n",
            "Episode length: 3511.80 +/- 797.56\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.51e+03 |\n",
            "|    mean_reward      | 521      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 850000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0414   |\n",
            "|    n_updates        | 187499   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.55e+03 |\n",
            "|    ep_rew_mean      | 500      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3500     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3821     |\n",
            "|    total_timesteps  | 851187   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.023    |\n",
            "|    n_updates        | 187796   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.57e+03 |\n",
            "|    ep_rew_mean      | 502      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3504     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3826     |\n",
            "|    total_timesteps  | 852135   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0176   |\n",
            "|    n_updates        | 188033   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.6e+03  |\n",
            "|    ep_rew_mean      | 508      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3508     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3833     |\n",
            "|    total_timesteps  | 853790   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0198   |\n",
            "|    n_updates        | 188447   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.6e+03  |\n",
            "|    ep_rew_mean      | 508      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3512     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3840     |\n",
            "|    total_timesteps  | 855304   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0195   |\n",
            "|    n_updates        | 188825   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.61e+03 |\n",
            "|    ep_rew_mean      | 507      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3516     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3845     |\n",
            "|    total_timesteps  | 856293   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0263   |\n",
            "|    n_updates        | 189073   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.63e+03 |\n",
            "|    ep_rew_mean      | 514      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3520     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3849     |\n",
            "|    total_timesteps  | 857275   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0229   |\n",
            "|    n_updates        | 189318   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.61e+03 |\n",
            "|    ep_rew_mean      | 511      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3524     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3854     |\n",
            "|    total_timesteps  | 858425   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.013    |\n",
            "|    n_updates        | 189606   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.62e+03 |\n",
            "|    ep_rew_mean      | 512      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3528     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3858     |\n",
            "|    total_timesteps  | 859416   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0148   |\n",
            "|    n_updates        | 189853   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.62e+03 |\n",
            "|    ep_rew_mean      | 518      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3532     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3866     |\n",
            "|    total_timesteps  | 861012   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0375   |\n",
            "|    n_updates        | 190252   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.63e+03 |\n",
            "|    ep_rew_mean      | 516      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3536     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3871     |\n",
            "|    total_timesteps  | 862238   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0179   |\n",
            "|    n_updates        | 190559   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.63e+03 |\n",
            "|    ep_rew_mean      | 515      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3540     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3878     |\n",
            "|    total_timesteps  | 863822   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0239   |\n",
            "|    n_updates        | 190955   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.66e+03 |\n",
            "|    ep_rew_mean      | 525      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3544     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3890     |\n",
            "|    total_timesteps  | 866434   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0394   |\n",
            "|    n_updates        | 191608   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.7e+03  |\n",
            "|    ep_rew_mean      | 528      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3548     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3897     |\n",
            "|    total_timesteps  | 868054   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0627   |\n",
            "|    n_updates        | 192013   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.69e+03 |\n",
            "|    ep_rew_mean      | 525      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3552     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3903     |\n",
            "|    total_timesteps  | 869276   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0224   |\n",
            "|    n_updates        | 192318   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.68e+03 |\n",
            "|    ep_rew_mean      | 525      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3556     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3909     |\n",
            "|    total_timesteps  | 870592   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0411   |\n",
            "|    n_updates        | 192647   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.69e+03 |\n",
            "|    ep_rew_mean      | 526      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3560     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3914     |\n",
            "|    total_timesteps  | 871855   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0127   |\n",
            "|    n_updates        | 192963   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.69e+03 |\n",
            "|    ep_rew_mean      | 529      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3564     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3919     |\n",
            "|    total_timesteps  | 872839   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0154   |\n",
            "|    n_updates        | 193209   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.7e+03  |\n",
            "|    ep_rew_mean      | 529      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3568     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3924     |\n",
            "|    total_timesteps  | 873952   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0237   |\n",
            "|    n_updates        | 193487   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.7e+03  |\n",
            "|    ep_rew_mean      | 532      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3572     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3928     |\n",
            "|    total_timesteps  | 874958   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.036    |\n",
            "|    n_updates        | 193739   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=875000, episode_reward=445.00 +/- 256.67\n",
            "Episode length: 3515.60 +/- 1673.86\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.52e+03 |\n",
            "|    mean_reward      | 445      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 875000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0247   |\n",
            "|    n_updates        | 193749   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.71e+03 |\n",
            "|    ep_rew_mean      | 535      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3576     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3943     |\n",
            "|    total_timesteps  | 876288   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.05     |\n",
            "|    n_updates        | 194071   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.71e+03 |\n",
            "|    ep_rew_mean      | 537      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3580     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3949     |\n",
            "|    total_timesteps  | 877427   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0181   |\n",
            "|    n_updates        | 194356   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.72e+03 |\n",
            "|    ep_rew_mean      | 541      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3584     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3956     |\n",
            "|    total_timesteps  | 878938   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0392   |\n",
            "|    n_updates        | 194734   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.71e+03 |\n",
            "|    ep_rew_mean      | 537      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3588     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3962     |\n",
            "|    total_timesteps  | 880334   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0227   |\n",
            "|    n_updates        | 195083   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.71e+03 |\n",
            "|    ep_rew_mean      | 538      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3592     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3966     |\n",
            "|    total_timesteps  | 881315   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0424   |\n",
            "|    n_updates        | 195328   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.68e+03 |\n",
            "|    ep_rew_mean      | 531      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3596     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3973     |\n",
            "|    total_timesteps  | 882781   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0275   |\n",
            "|    n_updates        | 195695   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.73e+03 |\n",
            "|    ep_rew_mean      | 542      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3600     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3985     |\n",
            "|    total_timesteps  | 885452   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0235   |\n",
            "|    n_updates        | 196362   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.72e+03 |\n",
            "|    ep_rew_mean      | 542      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3604     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3990     |\n",
            "|    total_timesteps  | 886621   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.028    |\n",
            "|    n_updates        | 196655   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.72e+03 |\n",
            "|    ep_rew_mean      | 541      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3608     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 3995     |\n",
            "|    total_timesteps  | 887853   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0133   |\n",
            "|    n_updates        | 196963   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.71e+03 |\n",
            "|    ep_rew_mean      | 541      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3612     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 4000     |\n",
            "|    total_timesteps  | 888832   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0269   |\n",
            "|    n_updates        | 197207   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.71e+03 |\n",
            "|    ep_rew_mean      | 543      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3616     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 4005     |\n",
            "|    total_timesteps  | 890138   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0166   |\n",
            "|    n_updates        | 197534   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.71e+03 |\n",
            "|    ep_rew_mean      | 544      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3620     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 4008     |\n",
            "|    total_timesteps  | 890768   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.04     |\n",
            "|    n_updates        | 197691   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.7e+03  |\n",
            "|    ep_rew_mean      | 543      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3624     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 4012     |\n",
            "|    total_timesteps  | 891553   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0185   |\n",
            "|    n_updates        | 197888   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.69e+03 |\n",
            "|    ep_rew_mean      | 545      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3628     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 4017     |\n",
            "|    total_timesteps  | 892748   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0139   |\n",
            "|    n_updates        | 198186   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.7e+03  |\n",
            "|    ep_rew_mean      | 549      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3632     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 4023     |\n",
            "|    total_timesteps  | 894115   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0173   |\n",
            "|    n_updates        | 198528   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.68e+03 |\n",
            "|    ep_rew_mean      | 546      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3636     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 4028     |\n",
            "|    total_timesteps  | 895354   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0587   |\n",
            "|    n_updates        | 198838   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.69e+03 |\n",
            "|    ep_rew_mean      | 550      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3640     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 4034     |\n",
            "|    total_timesteps  | 896613   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0152   |\n",
            "|    n_updates        | 199153   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.68e+03 |\n",
            "|    ep_rew_mean      | 549      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3644     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 4038     |\n",
            "|    total_timesteps  | 897413   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0258   |\n",
            "|    n_updates        | 199353   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.67e+03 |\n",
            "|    ep_rew_mean      | 548      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3648     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 4042     |\n",
            "|    total_timesteps  | 898393   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0179   |\n",
            "|    n_updates        | 199598   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.66e+03 |\n",
            "|    ep_rew_mean      | 548      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3652     |\n",
            "|    fps              | 222      |\n",
            "|    time_elapsed     | 4047     |\n",
            "|    total_timesteps  | 899442   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0463   |\n",
            "|    n_updates        | 199860   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=900000, episode_reward=500.00 +/- 196.85\n",
            "Episode length: 3557.00 +/- 718.04\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.56e+03 |\n",
            "|    mean_reward      | 500      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 900000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0223   |\n",
            "|    n_updates        | 199999   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.66e+03 |\n",
            "|    ep_rew_mean      | 548      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3656     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4061     |\n",
            "|    total_timesteps  | 900480   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0184   |\n",
            "|    n_updates        | 200119   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.67e+03 |\n",
            "|    ep_rew_mean      | 547      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3660     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4068     |\n",
            "|    total_timesteps  | 902073   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0256   |\n",
            "|    n_updates        | 200518   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.66e+03 |\n",
            "|    ep_rew_mean      | 547      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3664     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4073     |\n",
            "|    total_timesteps  | 903045   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.021    |\n",
            "|    n_updates        | 200761   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.64e+03 |\n",
            "|    ep_rew_mean      | 543      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3668     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4076     |\n",
            "|    total_timesteps  | 903740   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0331   |\n",
            "|    n_updates        | 200934   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.64e+03 |\n",
            "|    ep_rew_mean      | 545      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3672     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4083     |\n",
            "|    total_timesteps  | 905222   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0136   |\n",
            "|    n_updates        | 201305   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.64e+03 |\n",
            "|    ep_rew_mean      | 540      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3676     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4087     |\n",
            "|    total_timesteps  | 906176   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0127   |\n",
            "|    n_updates        | 201543   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.64e+03 |\n",
            "|    ep_rew_mean      | 537      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3680     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4095     |\n",
            "|    total_timesteps  | 907945   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0436   |\n",
            "|    n_updates        | 201986   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.63e+03 |\n",
            "|    ep_rew_mean      | 536      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3684     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4101     |\n",
            "|    total_timesteps  | 909344   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0377   |\n",
            "|    n_updates        | 202335   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.6e+03  |\n",
            "|    ep_rew_mean      | 532      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3688     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4108     |\n",
            "|    total_timesteps  | 910915   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0178   |\n",
            "|    n_updates        | 202728   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.6e+03  |\n",
            "|    ep_rew_mean      | 532      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3692     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4112     |\n",
            "|    total_timesteps  | 911877   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0255   |\n",
            "|    n_updates        | 202969   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.58e+03 |\n",
            "|    ep_rew_mean      | 526      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3696     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4116     |\n",
            "|    total_timesteps  | 912579   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0554   |\n",
            "|    n_updates        | 203144   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.59e+03 |\n",
            "|    ep_rew_mean      | 527      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3700     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4121     |\n",
            "|    total_timesteps  | 913795   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0855   |\n",
            "|    n_updates        | 203448   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.58e+03 |\n",
            "|    ep_rew_mean      | 526      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3704     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4125     |\n",
            "|    total_timesteps  | 914770   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0197   |\n",
            "|    n_updates        | 203692   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.54e+03 |\n",
            "|    ep_rew_mean      | 518      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3708     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4128     |\n",
            "|    total_timesteps  | 915279   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0188   |\n",
            "|    n_updates        | 203819   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 517      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3712     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4134     |\n",
            "|    total_timesteps  | 916808   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0171   |\n",
            "|    n_updates        | 204201   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 516      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3716     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4140     |\n",
            "|    total_timesteps  | 917919   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0148   |\n",
            "|    n_updates        | 204479   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.55e+03 |\n",
            "|    ep_rew_mean      | 517      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3720     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4145     |\n",
            "|    total_timesteps  | 919234   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0777   |\n",
            "|    n_updates        | 204808   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 514      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3724     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4151     |\n",
            "|    total_timesteps  | 920391   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0226   |\n",
            "|    n_updates        | 205097   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.55e+03 |\n",
            "|    ep_rew_mean      | 517      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3728     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4156     |\n",
            "|    total_timesteps  | 921552   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0243   |\n",
            "|    n_updates        | 205387   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.55e+03 |\n",
            "|    ep_rew_mean      | 519      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3732     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4160     |\n",
            "|    total_timesteps  | 922555   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.025    |\n",
            "|    n_updates        | 205638   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.55e+03 |\n",
            "|    ep_rew_mean      | 519      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3736     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4166     |\n",
            "|    total_timesteps  | 923756   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0155   |\n",
            "|    n_updates        | 205938   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=925000, episode_reward=435.00 +/- 83.31\n",
            "Episode length: 3753.00 +/- 893.18\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.75e+03 |\n",
            "|    mean_reward      | 435      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 925000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0594   |\n",
            "|    n_updates        | 206249   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.54e+03 |\n",
            "|    ep_rew_mean      | 522      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3740     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4182     |\n",
            "|    total_timesteps  | 925181   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0145   |\n",
            "|    n_updates        | 206295   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.55e+03 |\n",
            "|    ep_rew_mean      | 525      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3744     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4187     |\n",
            "|    total_timesteps  | 926460   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0113   |\n",
            "|    n_updates        | 206614   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 517      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3748     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4195     |\n",
            "|    total_timesteps  | 928261   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0329   |\n",
            "|    n_updates        | 207065   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.56e+03 |\n",
            "|    ep_rew_mean      | 518      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3752     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4202     |\n",
            "|    total_timesteps  | 929738   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0184   |\n",
            "|    n_updates        | 207434   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.55e+03 |\n",
            "|    ep_rew_mean      | 514      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3756     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4206     |\n",
            "|    total_timesteps  | 930794   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0352   |\n",
            "|    n_updates        | 207698   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.57e+03 |\n",
            "|    ep_rew_mean      | 520      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3760     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4214     |\n",
            "|    total_timesteps  | 932528   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0172   |\n",
            "|    n_updates        | 208131   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.58e+03 |\n",
            "|    ep_rew_mean      | 524      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3764     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4220     |\n",
            "|    total_timesteps  | 933755   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0277   |\n",
            "|    n_updates        | 208438   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.58e+03 |\n",
            "|    ep_rew_mean      | 523      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3768     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4224     |\n",
            "|    total_timesteps  | 934660   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0274   |\n",
            "|    n_updates        | 208664   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.57e+03 |\n",
            "|    ep_rew_mean      | 521      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3772     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4230     |\n",
            "|    total_timesteps  | 936042   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0323   |\n",
            "|    n_updates        | 209010   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.59e+03 |\n",
            "|    ep_rew_mean      | 523      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3776     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4234     |\n",
            "|    total_timesteps  | 936995   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0389   |\n",
            "|    n_updates        | 209248   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.56e+03 |\n",
            "|    ep_rew_mean      | 524      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3780     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4240     |\n",
            "|    total_timesteps  | 938269   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0286   |\n",
            "|    n_updates        | 209567   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.55e+03 |\n",
            "|    ep_rew_mean      | 522      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3784     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4243     |\n",
            "|    total_timesteps  | 939138   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0193   |\n",
            "|    n_updates        | 209784   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 522      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3788     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4249     |\n",
            "|    total_timesteps  | 940390   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0232   |\n",
            "|    n_updates        | 210097   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 519      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3792     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4253     |\n",
            "|    total_timesteps  | 941191   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0191   |\n",
            "|    n_updates        | 210297   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 521      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3796     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4258     |\n",
            "|    total_timesteps  | 942404   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0565   |\n",
            "|    n_updates        | 210600   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.54e+03 |\n",
            "|    ep_rew_mean      | 527      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3800     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4268     |\n",
            "|    total_timesteps  | 944699   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0183   |\n",
            "|    n_updates        | 211174   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.55e+03 |\n",
            "|    ep_rew_mean      | 532      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3804     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4274     |\n",
            "|    total_timesteps  | 945958   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0381   |\n",
            "|    n_updates        | 211489   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.54e+03 |\n",
            "|    ep_rew_mean      | 528      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3808     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4278     |\n",
            "|    total_timesteps  | 946834   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0242   |\n",
            "|    n_updates        | 211708   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.54e+03 |\n",
            "|    ep_rew_mean      | 528      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3812     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4283     |\n",
            "|    total_timesteps  | 947922   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0505   |\n",
            "|    n_updates        | 211980   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 526      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3816     |\n",
            "|    fps              | 221      |\n",
            "|    time_elapsed     | 4286     |\n",
            "|    total_timesteps  | 948822   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0343   |\n",
            "|    n_updates        | 212205   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=950000, episode_reward=438.00 +/- 139.91\n",
            "Episode length: 2927.40 +/- 604.04\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 2.93e+03 |\n",
            "|    mean_reward      | 438      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 950000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0584   |\n",
            "|    n_updates        | 212499   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.52e+03 |\n",
            "|    ep_rew_mean      | 527      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3820     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4300     |\n",
            "|    total_timesteps  | 950058   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0162   |\n",
            "|    n_updates        | 212514   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.52e+03 |\n",
            "|    ep_rew_mean      | 525      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3824     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4304     |\n",
            "|    total_timesteps  | 951125   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.021    |\n",
            "|    n_updates        | 212781   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.5e+03  |\n",
            "|    ep_rew_mean      | 521      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3828     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4308     |\n",
            "|    total_timesteps  | 951740   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0174   |\n",
            "|    n_updates        | 212934   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 513      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3832     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4314     |\n",
            "|    total_timesteps  | 953083   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.024    |\n",
            "|    n_updates        | 213270   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 515      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3836     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4322     |\n",
            "|    total_timesteps  | 954803   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0221   |\n",
            "|    n_updates        | 213700   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 518      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3840     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4325     |\n",
            "|    total_timesteps  | 955568   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0143   |\n",
            "|    n_updates        | 213891   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 517      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3844     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4333     |\n",
            "|    total_timesteps  | 957359   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0199   |\n",
            "|    n_updates        | 214339   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.49e+03 |\n",
            "|    ep_rew_mean      | 524      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3848     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4339     |\n",
            "|    total_timesteps  | 958674   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0207   |\n",
            "|    n_updates        | 214668   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 524      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3852     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4344     |\n",
            "|    total_timesteps  | 959821   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0156   |\n",
            "|    n_updates        | 214955   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.51e+03 |\n",
            "|    ep_rew_mean      | 525      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3856     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4352     |\n",
            "|    total_timesteps  | 961652   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0182   |\n",
            "|    n_updates        | 215412   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.49e+03 |\n",
            "|    ep_rew_mean      | 523      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3860     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4357     |\n",
            "|    total_timesteps  | 962675   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.015    |\n",
            "|    n_updates        | 215668   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.49e+03 |\n",
            "|    ep_rew_mean      | 519      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3864     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4362     |\n",
            "|    total_timesteps  | 963847   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0208   |\n",
            "|    n_updates        | 215961   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.49e+03 |\n",
            "|    ep_rew_mean      | 520      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3868     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4368     |\n",
            "|    total_timesteps  | 965055   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0277   |\n",
            "|    n_updates        | 216263   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.48e+03 |\n",
            "|    ep_rew_mean      | 518      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3872     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4373     |\n",
            "|    total_timesteps  | 966295   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0155   |\n",
            "|    n_updates        | 216573   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.48e+03 |\n",
            "|    ep_rew_mean      | 519      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3876     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4380     |\n",
            "|    total_timesteps  | 967767   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0239   |\n",
            "|    n_updates        | 216941   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 516      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3880     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4385     |\n",
            "|    total_timesteps  | 969001   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0257   |\n",
            "|    n_updates        | 217250   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 507      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3884     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4388     |\n",
            "|    total_timesteps  | 969801   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.023    |\n",
            "|    n_updates        | 217450   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.41e+03 |\n",
            "|    ep_rew_mean      | 507      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3888     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4393     |\n",
            "|    total_timesteps  | 970889   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0198   |\n",
            "|    n_updates        | 217722   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.41e+03 |\n",
            "|    ep_rew_mean      | 505      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3892     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4398     |\n",
            "|    total_timesteps  | 971877   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0129   |\n",
            "|    n_updates        | 217969   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.41e+03 |\n",
            "|    ep_rew_mean      | 505      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3896     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4403     |\n",
            "|    total_timesteps  | 973077   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0327   |\n",
            "|    n_updates        | 218269   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.41e+03 |\n",
            "|    ep_rew_mean      | 505      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3900     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4407     |\n",
            "|    total_timesteps  | 973980   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0198   |\n",
            "|    n_updates        | 218494   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=975000, episode_reward=513.00 +/- 164.00\n",
            "Episode length: 3743.00 +/- 721.81\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.74e+03 |\n",
            "|    mean_reward      | 513      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 975000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0147   |\n",
            "|    n_updates        | 218749   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 507      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3904     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4424     |\n",
            "|    total_timesteps  | 975567   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0152   |\n",
            "|    n_updates        | 218891   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 506      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3908     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4429     |\n",
            "|    total_timesteps  | 976546   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0366   |\n",
            "|    n_updates        | 219136   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3912     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4433     |\n",
            "|    total_timesteps  | 977364   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0162   |\n",
            "|    n_updates        | 219340   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3916     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4437     |\n",
            "|    total_timesteps  | 978438   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0184   |\n",
            "|    n_updates        | 219609   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3920     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4441     |\n",
            "|    total_timesteps  | 979272   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00937  |\n",
            "|    n_updates        | 219817   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.39e+03 |\n",
            "|    ep_rew_mean      | 494      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3924     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4446     |\n",
            "|    total_timesteps  | 980362   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0199   |\n",
            "|    n_updates        | 220090   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3928     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4453     |\n",
            "|    total_timesteps  | 981771   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0248   |\n",
            "|    n_updates        | 220442   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3932     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4456     |\n",
            "|    total_timesteps  | 982665   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0458   |\n",
            "|    n_updates        | 220666   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 500      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3936     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4460     |\n",
            "|    total_timesteps  | 983600   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0185   |\n",
            "|    n_updates        | 220899   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.41e+03 |\n",
            "|    ep_rew_mean      | 503      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3940     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4468     |\n",
            "|    total_timesteps  | 985358   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0174   |\n",
            "|    n_updates        | 221339   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.39e+03 |\n",
            "|    ep_rew_mean      | 500      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3944     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4471     |\n",
            "|    total_timesteps  | 986091   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0114   |\n",
            "|    n_updates        | 221522   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.41e+03 |\n",
            "|    ep_rew_mean      | 502      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3948     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4478     |\n",
            "|    total_timesteps  | 987525   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.013    |\n",
            "|    n_updates        | 221881   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 502      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3952     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4481     |\n",
            "|    total_timesteps  | 988182   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0179   |\n",
            "|    n_updates        | 222045   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.39e+03 |\n",
            "|    ep_rew_mean      | 501      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3956     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4486     |\n",
            "|    total_timesteps  | 989363   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0363   |\n",
            "|    n_updates        | 222340   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.39e+03 |\n",
            "|    ep_rew_mean      | 507      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3960     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4493     |\n",
            "|    total_timesteps  | 990830   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0317   |\n",
            "|    n_updates        | 222707   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.39e+03 |\n",
            "|    ep_rew_mean      | 508      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3964     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4500     |\n",
            "|    total_timesteps  | 992452   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0244   |\n",
            "|    n_updates        | 223112   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.38e+03 |\n",
            "|    ep_rew_mean      | 505      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3968     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4504     |\n",
            "|    total_timesteps  | 993510   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0192   |\n",
            "|    n_updates        | 223377   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.41e+03 |\n",
            "|    ep_rew_mean      | 511      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3972     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4509     |\n",
            "|    total_timesteps  | 994642   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0173   |\n",
            "|    n_updates        | 223660   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.42e+03 |\n",
            "|    ep_rew_mean      | 516      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3976     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4516     |\n",
            "|    total_timesteps  | 996219   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0467   |\n",
            "|    n_updates        | 224054   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 517      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3980     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4521     |\n",
            "|    total_timesteps  | 997259   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0595   |\n",
            "|    n_updates        | 224314   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.47e+03 |\n",
            "|    ep_rew_mean      | 523      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3984     |\n",
            "|    fps              | 220      |\n",
            "|    time_elapsed     | 4529     |\n",
            "|    total_timesteps  | 999023   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0144   |\n",
            "|    n_updates        | 224755   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1000000, episode_reward=633.00 +/- 210.20\n",
            "Episode length: 4151.00 +/- 1514.59\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 4.15e+03 |\n",
            "|    mean_reward      | 633      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 1000000  |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0233   |\n",
            "|    n_updates        | 224999   |\n",
            "----------------------------------\n",
            "Saving to logs//dqn/SpaceInvadersNoFrameskip-v4_1\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/  -c dqn.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dLomIiMKQaf"
      },
      "source": [
        "## Let's evaluate our agent üëÄ\n",
        "- RL-Baselines3-Zoo provides `enjoy.py`, a python script to evaluate our agent. In most RL libraries, we call the evaluation script `enjoy.py`.\n",
        "- Let's evaluate it for 5000 timesteps üî•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "co5um_KeKbBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13d2d9f-d21d-4b40-cd43-dfa39d4364a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-22 00:00:47.221658: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753142447.242584   20929 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753142447.249013   20929 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-22 00:00:47.270331: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading latest experiment, id=1\n",
            "Loading logs/dqn/SpaceInvadersNoFrameskip-v4_1/SpaceInvadersNoFrameskip-v4.zip\n",
            "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
            "[Powered by Stella]\n",
            "Stacking 4 frames\n",
            "Atari Episode Score: 275.00\n",
            "Atari Episode Length 2597\n",
            "Atari Episode Score: 525.00\n",
            "Atari Episode Length 3877\n",
            "Atari Episode Score: 285.00\n",
            "Atari Episode Length 2351\n",
            "Atari Episode Score: 600.00\n",
            "Atari Episode Length 5349\n",
            "Atari Episode Score: 530.00\n",
            "Atari Episode Length 3973\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.enjoy  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --no-render  --n-timesteps 5000  --folder logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liBeTltiHJtr"
      },
      "source": [
        "## Publish our trained model on the Hub üöÄ\n",
        "Now that we saw we got good results after the training, we can publish our trained model on the hub ü§ó with one line of code.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit3/space-invaders-model.gif\" alt=\"Space Invaders model\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezbHS1q3HYVV"
      },
      "source": [
        "By using `rl_zoo3.push_to_hub` **you evaluate, record a replay, generate a model card of your agent and push it to the hub**.\n",
        "\n",
        "This way:\n",
        "- You can **showcase our work** üî•\n",
        "- You can **visualize your agent playing** üëÄ\n",
        "- You can **share with the community an agent that others can use** üíæ\n",
        "- You can **access a leaderboard üèÜ to see how well your agent is performing compared to your classmates** üëâ  https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMSeZRBiHk6X"
      },
      "source": [
        "To be able to share your model with the community there are three more steps to follow:\n",
        "\n",
        "1Ô∏è‚É£ (If it's not already done) create an account to HF ‚û° https://huggingface.co/join\n",
        "\n",
        "2Ô∏è‚É£ Sign in and then, you need to store your authentication token from the Hugging Face website.\n",
        "- Create a new token (https://huggingface.co/settings/tokens) **with write role**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O6FI0F8HnzE"
      },
      "source": [
        "- Copy the token\n",
        "- Run the cell below and past the token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ppu9yePwHrZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "c26eea8aa9dc45608e82e29c92fcf1e6",
            "6e9c827e6a084bf0b94d7631bf526c54",
            "134ab04e5ee845dbafd260691211f1c1",
            "cc2bad1d457f46eba9c884979ba54640",
            "6fc28bf00da54827aab2e7a6fac35aea",
            "acef9e07715d495482210a55ae5501bc",
            "f2c483b1b38244b4b3bcfee510d96dc9",
            "1fcedc7530434ac0ba55ec16b5e6624a",
            "54083585790f4239a271c1b59eb3be47",
            "e47feb9f44b848abbf03cf107ab1356b",
            "92905a3ec1d1480784e78b31723fe65a",
            "06ea824497d64eef92dba4b85e4fe62e",
            "458b39b03fd2499aadead2abfdd48470",
            "1b952c6e1cb84a1589ee68b20ce56733",
            "4703dc4f8a314dde989d9b266d9d1deb",
            "58440e7a772a45c39845a35a356d5fe1",
            "7a840273d5d34cdc9205c437cba75ace",
            "b247c48b90c847c493ed24a86aa446f3",
            "eda5c5feef154e2ea72976f0d35e155b",
            "28884a78e9144a2e9f0ce7dc191b6cf9"
          ]
        },
        "outputId": "95548169-da34-4c6c-c420-6b7ac527a1b3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c26eea8aa9dc45608e82e29c92fcf1e6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n",
        "notebook_login()\n",
        "!git config --global credential.helper store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RVEdunPHs8B"
      },
      "source": [
        "If you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command instead: `huggingface-cli login`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSLwdmvhHvjw"
      },
      "source": [
        "3Ô∏è‚É£ We're now ready to push our trained agent to the ü§ó Hub üî•"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW436XnhHw1H"
      },
      "source": [
        "Let's run push_to_hub.py file to upload our trained agent to the Hub.\n",
        "\n",
        "`--repo-name `: The name of the repo\n",
        "\n",
        "`-orga`: Your Hugging Face username\n",
        "\n",
        "`-f`: Where the trained model folder is (in our case `logs`)\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit3/select-id.png\" alt=\"Select Id\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ygk2sEktTDEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d924e1-0e24-428c-a976-898932f5127d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-22 00:09:15.315297: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753142955.341647   23119 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753142955.352444   23119 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-22 00:09:15.377761: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading latest experiment, id=1\n",
            "Loading logs/dqn/SpaceInvadersNoFrameskip-v4_1/SpaceInvadersNoFrameskip-v4.zip\n",
            "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
            "[Powered by Stella]\n",
            "Stacking 4 frames\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Uploading to MarioBarbeque/dqn-SpaceInvadersNoFrameskip-v4, make sure to have the rights\n",
            "\u001b[38;5;4m‚Ñπ This function will save, evaluate, generate a video of your agent,\n",
            "create a model card and push everything to the hub. It might take up to some\n",
            "minutes if video generation is activated. This is a work in progress: if you\n",
            "encounter a bug, please open an issue.\u001b[0m\n",
            "Fetching 14 files:   0% 0/14 [00:00<?, ?it/s]\n",
            "config.yml: 100% 550/550 [00:00<00:00, 3.10MB/s]\n",
            "\n",
            ".gitattributes: 1.56kB [00:00, 4.98MB/s]\n",
            "Fetching 14 files:   7% 1/14 [00:00<00:03,  3.33it/s]\n",
            "args.yml: 1.27kB [00:00, 5.71MB/s]\n",
            "\n",
            "README.md: 2.82kB [00:00, 6.66MB/s]\n",
            "\n",
            "_stable_baselines3_version: 100% 7.00/7.00 [00:00<00:00, 72.1kB/s]\n",
            "\n",
            "data: 205kB [00:00, 34.5MB/s]\n",
            "\n",
            "env_kwargs.yml: 100% 23.0/23.0 [00:00<00:00, 187kB/s]\n",
            "\n",
            "results.json: 100% 153/153 [00:00<00:00, 1.69MB/s]\n",
            "\n",
            "system_info.txt: 100% 262/262 [00:00<00:00, 2.93MB/s]\n",
            "Fetching 14 files: 100% 14/14 [00:00<00:00, 22.76it/s]\n",
            "Saving model to: hub/dqn-SpaceInvadersNoFrameskip-v4/dqn-SpaceInvadersNoFrameskip-v4\n",
            "Saving video to /tmp/tmp506cvc5h/-step-0-to-step-1000.mp4\n",
            "Moviepy - Building video /tmp/tmp506cvc5h/-step-0-to-step-1000.mp4.\n",
            "Moviepy - Writing video /tmp/tmp506cvc5h/-step-0-to-step-1000.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready /tmp/tmp506cvc5h/-step-0-to-step-1000.mp4\n",
            "\u001b[38;5;1m‚úò 'DummyVecEnv' object has no attribute 'video_recorder'\u001b[0m\n",
            "\u001b[38;5;1m‚úò We are unable to generate a replay of your agent, the package_to_hub\n",
            "process continues\u001b[0m\n",
            "\u001b[38;5;1m‚úò Please open an issue at\n",
            "https://github.com/huggingface/huggingface_sb3/issues\u001b[0m\n",
            "\u001b[38;5;4m‚Ñπ Pushing repo dqn-SpaceInvadersNoFrameskip-v4 to the Hugging Face\n",
            "Hub\u001b[0m\n",
            "dqn-SpaceInvadersNoFrameskip-v4.zip: 100% 27.2M/27.2M [00:01<00:00, 14.4MB/s]\n",
            "\u001b[38;5;4m‚Ñπ Your model is pushed to the hub. You can view your model here:\n",
            "https://huggingface.co/MarioBarbeque/dqn-SpaceInvadersNoFrameskip-v4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.push_to_hub  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --repo-name dqn-SpaceInvadersNoFrameskip-v4 -orga MarioBarbeque -f logs/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /tmp && ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXyyRZwjeSi2",
        "outputId": "3ee6c211-e3c2-44a4-8ce1-cd66ca6edab2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "colab_runtime.sock\n",
            "dap_multiplexer.fa81e510fc43.root.log.INFO.20250721-223616.114\n",
            "dap_multiplexer.INFO\n",
            "debugger_3mt9ztsfi\n",
            "initgoogle_syslog_dir.0\n",
            "language_service.fa81e510fc43.root.log.INFO.20250721-223938.969\n",
            "language_service.fa81e510fc43.root.log.INFO.20250722-000107.21032\n",
            "language_service.INFO\n",
            "pyright-21038-EtcQSyMPw5Zk\n",
            "pyright-21038-hAEN9Pqnqe4Y\n",
            "pyright-979-njJ50Dzh9xsQ\n",
            "python-languageserver-cancellation\n",
            "SB3-2025-07-21-22-44-56-060094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otgpa0rhS9wR"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HQNlAXuEhci"
      },
      "outputs": [],
      "source": [
        "!python -m rl_zoo3.push_to_hub  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --repo-name dqn-SpaceInvadersNoFrameskip-v4  -orga ThomasSimonini  -f logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D4F5zsTTJ-L"
      },
      "source": [
        "###."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff89kd2HL1_s"
      },
      "source": [
        "Congrats ü•≥ you've just trained and uploaded your first Deep Q-Learning agent using RL-Baselines-3 Zoo. The script above should have displayed a link to a model repository such as https://huggingface.co/ThomasSimonini/dqn-SpaceInvadersNoFrameskip-v4. When you go to this link, you can:\n",
        "\n",
        "- See a **video preview of your agent** at the right.\n",
        "- Click \"Files and versions\" to see all the files in the repository.\n",
        "- Click \"Use in stable-baselines3\" to get a code snippet that shows how to load the model.\n",
        "- A model card (`README.md` file) which gives a description of the model and the hyperparameters you used.\n",
        "\n",
        "Under the hood, the Hub uses git-based repositories (don't worry if you don't know what git is), which means you can update the model with new versions as you experiment and improve your agent.\n",
        "\n",
        "**Compare the results of your agents with your classmates** using the [leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) üèÜ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyRKcCYY-dIo"
      },
      "source": [
        "## Load a powerful trained model üî•\n",
        "- The Stable-Baselines3 team uploaded **more than 150 trained Deep Reinforcement Learning agents on the Hub**.\n",
        "\n",
        "You can find them here: üëâ https://huggingface.co/sb3\n",
        "\n",
        "Some examples:\n",
        "- Asteroids: https://huggingface.co/sb3/dqn-AsteroidsNoFrameskip-v4\n",
        "- Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4\n",
        "- Breakout: https://huggingface.co/sb3/dqn-BreakoutNoFrameskip-v4\n",
        "- Road Runner: https://huggingface.co/sb3/dqn-RoadRunnerNoFrameskip-v4\n",
        "\n",
        "Let's load an agent playing Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-9QVFIROI5Y"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<video controls autoplay><source src=\"https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZQNY_r6NJtC"
      },
      "source": [
        "1. We download the model using `rl_zoo3.load_from_hub`, and place it in a new folder that we can call `rl_trained`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdBNZHy0NGTR"
      },
      "outputs": [],
      "source": [
        "# Download model and save it into the logs/ folder\n",
        "!python -m rl_zoo3.load_from_hub --algo dqn --env BeamRiderNoFrameskip-v4 -orga sb3 -f rl_trained/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFt6hmWsNdBo"
      },
      "source": [
        "2. Let's evaluate if for 5000 timesteps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOxs0rNuN0uS"
      },
      "outputs": [],
      "source": [
        "!python -m rl_zoo3.enjoy --algo dqn --env BeamRiderNoFrameskip-v4 -n 5000  -f rl_trained/ --no-render"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxMDuDfPON57"
      },
      "source": [
        "Why not trying to train your own **Deep Q-Learning Agent playing BeamRiderNoFrameskip-v4? üèÜ.**\n",
        "\n",
        "If you want to try, check https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4#hyperparameters **in the model card, you have the hyperparameters of the trained agent.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL_ZtUgpOuY6"
      },
      "source": [
        "But finding hyperparameters can be a daunting task. Fortunately, we'll see in the next Unit, how we can **use Optuna for optimizing the Hyperparameters üî•.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pqaco8W-huW"
      },
      "source": [
        "## Some additional challenges üèÜ\n",
        "The best way to learn **is to try things by your own**!\n",
        "\n",
        "In the [Leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) you will find your agents. Can you get to the top?\n",
        "\n",
        "Here's a list of environments you can try to train your agent with:\n",
        "- BeamRiderNoFrameskip-v4\n",
        "- BreakoutNoFrameskip-v4\n",
        "- EnduroNoFrameskip-v4\n",
        "- PongNoFrameskip-v4\n",
        "\n",
        "Also, **if you want to learn to implement Deep Q-Learning by yourself**, you definitely should look at CleanRL implementation: https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/atari-envs.gif\" alt=\"Environments\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paS-XKo4-kmu"
      },
      "source": [
        "________________________________________________________________________\n",
        "Congrats on finishing this chapter!\n",
        "\n",
        "If you‚Äôre still feel confused with all these elements...it's totally normal! **This was the same for me and for all people who studied RL.**\n",
        "\n",
        "Take time to really **grasp the material before continuing and try the additional challenges**. It‚Äôs important to master these elements and having a solid foundations.\n",
        "\n",
        "In the next unit, **we‚Äôre going to learn about [Optuna](https://optuna.org/)**. One of the most critical task in Deep Reinforcement Learning is to find a good set of training hyperparameters. And Optuna is a library that helps you to automate the search.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WRx7tO7-mvC"
      },
      "source": [
        "\n",
        "\n",
        "### This is a course built with you üë∑üèø‚Äç‚ôÄÔ∏è\n",
        "\n",
        "Finally, we want to improve and update the course iteratively with your feedback. If you have some, please fill this form üëâ https://forms.gle/3HgA7bEHwAmmLfwh9\n",
        "\n",
        "We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See you on Bonus unit 2! üî•"
      ],
      "metadata": {
        "id": "Kc3udPT-RcXc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS3Xerx0fIMV"
      },
      "source": [
        "### Keep Learning, Stay Awesome ü§ó"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "22049c55",
        "outputId": "c571436f-058d-4c39-cf3d-f99de4efea37"
      },
      "source": [
        "# gemini help\n",
        "\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder\n",
        "\n",
        "# Define the environment ID and the path to your trained model\n",
        "# env_id = \"SpaceInvadersNoFrameskip-v4\"\n",
        "env_id = \"SpaceInvadersNoFrameskip-v4\"\n",
        "model_path = \"logs/dqn/SpaceInvadersNoFrameskip-v4_1/SpaceInvadersNoFrameskip-v4.zip\"  # Adjust if your model path is different\n",
        "\n",
        "# Create the environment\n",
        "env = DummyVecEnv([lambda: gym.make(env_id)])\n",
        "\n",
        "# Wrap the environment with VecVideoRecorder\n",
        "# The video will be saved to the 'videos' folder\n",
        "video_folder = \"videos\"\n",
        "video_length = 1000  # Record 1000 timesteps\n",
        "env = VecVideoRecorder(env, video_folder,\n",
        "                       record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
        "                       vec_env_cls=DummyVecEnv)\n",
        "\n",
        "# Load the trained agent\n",
        "model = DQN.load(model_path, env=env)\n",
        "\n",
        "# Run a few episodes to record the video\n",
        "obs = env.reset()\n",
        "for _ in range(video_length):\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, info = env.step(action)\n",
        "\n",
        "# Close the video recorder\n",
        "env.close()\n",
        "\n",
        "print(f\"Video recorded and saved to the '{video_folder}' folder.\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameNotFound",
          "evalue": "Environment `SpaceInvadersNoFrameskip` doesn't exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-41-706798948.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Create the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummyVecEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Wrap the environment with VecVideoRecorder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_fns)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_fns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_patch_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menv_fns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0menv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_fns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_patch_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menv_fns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0menv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/tmp/ipython-input-41-706798948.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Create the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummyVecEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Wrap the environment with VecVideoRecorder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;31m# The environment name can include an unloaded module in \"module:env_name\" style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0menv_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(env_id)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0menv_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0m_check_version_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         raise error.Error(\n\u001b[1;32m    535\u001b[0m             \u001b[0;34mf\"No registered env with id: {env_name}. Did you register it, or import the package that registers it? Use `gymnasium.pprint_registry()` to see all of the registered environments.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0m_check_name_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0msuggestion_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\" Did you mean: `{suggestion[0]}`?\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msuggestion\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     raise error.NameNotFound(\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;34mf\"Environment `{name}` doesn't exist{namespace_msg}.{suggestion_msg}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     )\n",
            "\u001b[0;31mNameNotFound\u001b[0m: Environment `SpaceInvadersNoFrameskip` doesn't exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autorom[accept-rom-license]\n",
        "# Then run:\n",
        "!python -c \"import ale_py.roms\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s52Nv_EAi68h",
        "outputId": "be9be951-fcdc-42f3-9b7c-9d465b7e5edf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autorom[accept-rom-license]\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (8.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (2.32.3)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/434.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m225.3/434.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2025.7.14)\n",
            "Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446709 sha256=2a707f9c68f399eefad7d9cee7e2da2dc9f90f571be58582884680cdbee46e1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym  # or import gym\n",
        "print([env for env in gym.envs.registry.env_specs.keys() if 'SpaceInvaders' in env])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "TFaX-pUGisKk",
        "outputId": "8de34008-7ea3-43cf-d3ae-c7804d33c138"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'env_specs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-42-107677407.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgymnasium\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgym\u001b[0m  \u001b[0;31m# or import gym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0menv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_specs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'SpaceInvaders'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'env_specs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym  # or import gym\n",
        "\n",
        "# Method 1 - Works with most versions\n",
        "print([env_id for env_id in gym.envs.registry.keys() if 'SpaceInvaders' in env_id])\n",
        "\n",
        "# Method 2 - Alternative approach\n",
        "all_envs = list(gym.envs.registry.keys())\n",
        "space_invaders_envs = [env for env in all_envs if 'SpaceInvaders' in env]\n",
        "print(space_invaders_envs)\n",
        "\n",
        "# Method 3 - See all Atari environments\n",
        "atari_envs = [env for env in gym.envs.registry.keys() if 'ALE' in env or 'Atari' in env]\n",
        "print(\"Atari environments:\", atari_envs[:10])  # Show first 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSl8A6s9jP9k",
        "outputId": "1f392bf9-67f1-4585-bcd0-622a1629b7c6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[]\n",
            "Atari environments: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the base requirements\n",
        "!pip install gymnasium ale-py\n",
        "\n",
        "# Install AutoROM and accept ROM license\n",
        "!pip install autorom[accept-rom-license]\n",
        "\n",
        "# Import ROMs\n",
        "!python -c \"import ale_py; ale_py.roms.get_installed_roms()\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUtXcVo_jadp",
        "outputId": "26f4a139-f45b-4b85-e78a-229093c7ac5d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.11/dist-packages (0.11.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: autorom[accept-rom-license] in /usr/local/lib/python3.11/dist-packages (0.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (8.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (2.32.3)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2025.7.14)\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "AttributeError: module 'ale_py.roms' has no attribute 'get_installed_roms'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ale_py\n",
        "\n",
        "# Check available games\n",
        "print(\"Available games:\")\n",
        "print(ale_py.list_games())\n",
        "\n",
        "# Or check ROM directory\n",
        "print(\"\\nROM path:\")\n",
        "print(ale_py.ROM_DIR if hasattr(ale_py, 'ROM_DIR') else \"ROM_DIR not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "zbsfpRAvj4hF",
        "outputId": "72148514-8e56-446e-ed5f-b9b8b1816ea6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available games:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'ale_py' has no attribute 'list_games'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-47-1408789224.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Check available games\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available games:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0male_py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_games\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Or check ROM directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'ale_py' has no attribute 'list_games'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, uninstall existing packages\n",
        "!pip uninstall gymnasium gym ale-py atari-py autorom -y\n",
        "\n",
        "# Install everything fresh\n",
        "!pip install gymnasium\n",
        "!pip install \"ale-py[gym]>=0.8\"\n",
        "!pip install autorom\n",
        "!AutoROM --accept-license"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JMwXxvoHkF7f",
        "outputId": "25d86d5b-cd71-42b0-c6d8-fedfaf37b5d7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: gymnasium 1.1.1\n",
            "Uninstalling gymnasium-1.1.1:\n",
            "  Successfully uninstalled gymnasium-1.1.1\n",
            "Found existing installation: gym 0.26.2\n",
            "Uninstalling gym-0.26.2:\n",
            "  Successfully uninstalled gym-0.26.2\n",
            "Found existing installation: ale-py 0.11.2\n",
            "Uninstalling ale-py-0.11.2:\n",
            "  Successfully uninstalled ale-py-0.11.2\n",
            "\u001b[33mWARNING: Skipping atari-py as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: AutoROM 0.6.1\n",
            "Uninstalling AutoROM-0.6.1:\n",
            "  Successfully uninstalled AutoROM-0.6.1\n",
            "Collecting gymnasium\n",
            "  Downloading gymnasium-1.2.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Downloading gymnasium-1.2.0-py3-none-any.whl (944 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m944.3/944.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gymnasium\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, which is not installed.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "rl-zoo3 2.7.0a0 requires gymnasium<1.2.0,>=0.29.1, but you have gymnasium 1.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gymnasium"
                ]
              },
              "id": "35a5a42b0bec4f9ea5d0eee80d6d80d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ale-py>=0.8 (from ale-py[gym]>=0.8)\n",
            "  Using cached ale_py-0.11.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.11/dist-packages (from ale-py>=0.8->ale-py[gym]>=0.8) (2.0.2)\n",
            "\u001b[33mWARNING: ale-py 0.11.2 does not provide the extra 'gym'\u001b[0m\u001b[33m\n",
            "\u001b[0mUsing cached ale_py-0.11.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.1 MB)\n",
            "Installing collected packages: ale-py\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ale-py-0.11.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ale_py"
                ]
              },
              "id": "ed2d747b6c8047348fc4ac6ba2743e19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autorom\n",
            "  Using cached AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom) (8.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom) (2025.7.14)\n",
            "Using cached AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Installing collected packages: autorom\n",
            "Successfully installed autorom-0.6.1\n",
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/usr/local/lib/python3.11/dist-packages/AutoROM/roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e6eZ0_bzkQLd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c26eea8aa9dc45608e82e29c92fcf1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_f2c483b1b38244b4b3bcfee510d96dc9"
          }
        },
        "6e9c827e6a084bf0b94d7631bf526c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fcedc7530434ac0ba55ec16b5e6624a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_54083585790f4239a271c1b59eb3be47",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "134ab04e5ee845dbafd260691211f1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e47feb9f44b848abbf03cf107ab1356b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_92905a3ec1d1480784e78b31723fe65a",
            "value": ""
          }
        },
        "cc2bad1d457f46eba9c884979ba54640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_06ea824497d64eef92dba4b85e4fe62e",
            "style": "IPY_MODEL_458b39b03fd2499aadead2abfdd48470",
            "value": true
          }
        },
        "6fc28bf00da54827aab2e7a6fac35aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_1b952c6e1cb84a1589ee68b20ce56733",
            "style": "IPY_MODEL_4703dc4f8a314dde989d9b266d9d1deb",
            "tooltip": ""
          }
        },
        "acef9e07715d495482210a55ae5501bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58440e7a772a45c39845a35a356d5fe1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7a840273d5d34cdc9205c437cba75ace",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "f2c483b1b38244b4b3bcfee510d96dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "1fcedc7530434ac0ba55ec16b5e6624a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54083585790f4239a271c1b59eb3be47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e47feb9f44b848abbf03cf107ab1356b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92905a3ec1d1480784e78b31723fe65a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06ea824497d64eef92dba4b85e4fe62e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "458b39b03fd2499aadead2abfdd48470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b952c6e1cb84a1589ee68b20ce56733": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4703dc4f8a314dde989d9b266d9d1deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "58440e7a772a45c39845a35a356d5fe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a840273d5d34cdc9205c437cba75ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b247c48b90c847c493ed24a86aa446f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eda5c5feef154e2ea72976f0d35e155b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_28884a78e9144a2e9f0ce7dc191b6cf9",
            "value": "Connecting..."
          }
        },
        "eda5c5feef154e2ea72976f0d35e155b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28884a78e9144a2e9f0ce7dc191b6cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}